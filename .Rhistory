boxplot(Val~ID,data=scores,ylab='Val',log='y')
vs <- aggregate(Val,list(ID),sum,na.rm=T)
scoresSs <- sapply(c(T,F),function(o)
vs[order(vs$x,decreasing=o)[1:5],1])
colnames(scoresSs)<-c('Most','Least')
scoresSs
scores <- sales[ID %in% scoresSs[1,],c('ID','Val')]
scores$ID <- factor(scores$ID)
boxplot(Val~ID,data=scores,ylab='Val',log='y')
attach(sales)
upp <- aggregate(Uprice,list(Prod),median,na.rm=T)
topP <- sapply(c(T,F),function(o)
upp[order(upp[,2],decreasing=o)[1:5],1])
colnames(topP)<-c('Expensive','Cheap')
topP
tops <- sales[Prod %in% topP[1,],c('Prod','Uprice')]
tops$Prod <- factor(tops$Prod)
par(mfcol = c(1,2))
boxplot(Uprice~Prod, data=tops,ylab='Uprice',log='y')
vs <- aggregate(Val,list(ID),sum,na.rm=T)
scoresSs <- sapply(c(T,F),function(o)
vs[order(vs$x,decreasing=o)[1:5],1])
colnames(scoresSs)<-c('Most','Least')
scoresSs
scores <- sales[ID %in% scoresSs[1,],c('ID','Val')]
scores$ID <- factor(scores$ID)
boxplot(Val~ID,data=scores,ylab='Val',log='y')
sum(vs[order(vs$x,decreasing=T)[1:100],2])/sum(Val,na.rm=T)*100
sum(vs[order(vs$x,decreasing=F)[1:2000],2])/sum(Val,na.rm=T)*100
head(Val)
qs <- aggregate(Quant,list(Prod),sum,na.rm=T)
scoresPs <- sapply(c(T,F),function(x)
qs[order(qs$x,decreasing=o)[1:5,1]])
scoresPs <- sapply(c(T,F),function(o)
qs[order(qs$x,decreasing=o)[1:5,1]])
scoresPs <- sapply(c(T,F),function(o)
qs[order(qs$x,decreasing=o)[1:5,1])
scoresPs <- sapply(c(T,F),function(o)
qs[order(qs$x,decreasing=o)[1:5,1]]
)
scoresPs <- sapply(c(T,F),function(o)
qs[order(qs$x,decreasing=o)[1:5,1]])
scoresPs <- sapply(c(T,F),function(o)
qs[order(qs$x,decreasing=o)[1:5],1])
colnames(scoresPs) <- c('Most','Least')
scoresPs
sum(as.double(qs[order(qs$x,decreasing=T)[1:100],2]))/sum(as.double(Quant),na.rm=T)*100
sum(as.double(qs[order(qs$x,decreasing=F)[1:2000],2]))/sum(as.double(Quant),na.rm=T)*100
sum(as.double(qs[order(qs$x,decreasing=F)[1:4000],2]))/sum(as.double(Quant),na.rm=T)*100
head(Uprice)
list(Prod=Prod)
head(list(Prod=Prod))
head(Prod)
?tapply
ind <- list(c(1, 2, 2), c("A", "A", "B"))
table(ind)
out <- tapply(Uprice,list(Prod=Prod),function(x)length(boxplot.stats(x)$out))
out
out[order(out,decreasing = T)[1:10]]
sum(out)
sum(out)/nrow(sales)
sum(out)/nrow(sales)*100
source('data explorasion.R')
source('Data explorasion.R')
source('Data.explorasion.R')
source('Data_explorasion.R')
gc()
totS <- table(ID)
totP <- table(Prod)
head(totS)
nas <- sales[which(is.na(Quant)&is.na(Val)),c('ID','Prod')]
nas
propS <- 100*table(nan$ID)/totS
propS
propS <- 100*table(nas$ID)/totS
propS
head(propS)
propS[order(propS,decreasing=T)[1:10]]
propP <- 100*table(nas$Prod)/totP
head(propP)
propP[order(propP,decreasing=T)[1:10]]
detach(sales)
sales <- sales[-which(is.na(sales$Quant)&is.na(sales$Val)),]
nnasQp <- tapply(sales$Quant,list(sales$Prod),function(x)sum(is.na(x)))
propNAsQp <- nnasQp/table(sales$Prod)
propNAsQp[order(propNAsQp,decreasing=T)[1:10]]
sales <- sales[!sales$Prod %in% c('p2442','p2443'),]
nlevels(sales$Prod)
sales$Prod <- factor(sales$Prod)
nlevels(sales$Prod)
nnasQs <- tapply(sales$Quant,list(sales$ID),function(x)sum(is.na(x)))
propNAsQs <- nnasQs/table(sales$ID)
propNAsQs[order(propNAsQs,decreasing = T)[1:10]]
nnasVp <- tapply(sales$Val,list(sales$Prod),function(x)sum(is.na(x)))
propNAsVp<-nnasVp/table(sales$Val)
propNAsVp<-nnasVp/table(sales$Prod)
propNAsVp[order(propNAsVp,decreasing = T)[1:10]]
nnasVs <- tapply(sales$Val,list(sales$ID),function(x)sum(is.na(x)))
propNAsVs<-nnasVp/table(sales$ID)
propNAsVs[order(propNAsVp,decreasing = T)[1:10]]
propNAsVs<-nnasVs/table(sales$ID)
propNAsVs[order(propNAsVp,decreasing = T)[1:10]]
nnasVs <- tapply(sales$Val,list(sales$ID),function(x)sum(is.na(x)))
propNAsVs<-nnasVs/table(sales$ID)
propNAsVs[order(propNAsVs,decreasing = T)[1:10]]
setwd('C:\\Documents and Settings\\Macro\\Desktop\\Ivandata\\spam-filtering')
library('tm')
library('ggplot2')
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
spam.path
?runif
x <- runif(1000, 0, 40)
y1 <- cbind(runif(100, 0, 10), 1)
x
y1
y2 <- cbind(runif(800, 10, 30), 2)
y3 <- cbind(runif(100, 30, 40), 1)
val <- data.frame(cbind(x, rbind(y1, y2, y3)),
stringsAsFactors = TRUE)
ex1 <- ggplot(val, aes(x, V2)) +
geom_jitter(aes(shape = as.factor(V3)),
position = position_jitter(height = 2)) +
scale_shape_discrete(guide = "none", solid = FALSE) +
geom_hline(aes(yintercept = c(10,30)), linetype = 2) +
theme_bw() +
xlab("X") +
ylab("Y")
ggsave(plot = ex1,
filename = file.path("images", "00_Ex1.pdf"),
height = 10,
width = 10)
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
# Return a single element vector of just the email body
# This is a very simple approach, as we are only using
# words as features
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
spam.docs <- dir(spam.path)
spam.docs
spam.docs <- spam.docs[which(spam.docs != "cmds")]
spam.docs
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
spam.docs[1]
get.msg(file.path(spam.path, spam.docs[1]))
spam.path
file.path(spam.path, spam.docs[1])
con <- file(file.path(spam.path, spam.docs[1]), open = "rt", encoding = "latin1")
con
text <- readLines(con)
text
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
msg
seq(which(text == "")[1] + 1
all.spam <- sapply(spam.docs,function(p) get.msg(file.path(spam.path, p)))
spam.docs
get.msg(file.path(spam.path, spam.docs[2])
)
get.msg(file.path(spam.path, spam.docs[3]))
get.msg(file.path(spam.path, spam.docs[4]))
get.msg(file.path(spam.path, spam.docs[5]))
get.msg(file.path(spam.path, spam.docs[6]))
get.msg(file.path(spam.path, spam.docs[6]))
get.msg(file.path(spam.path, spam.docs[7]))
get.msg(file.path(spam.path, spam.docs[8]))
get.msg(file.path(spam.path, spam.docs[9]))
sapply(spam.docs,function(p) get.msg(file.path(spam.path, p)))
sapply(spam.docs,function(p) get.msg(file.path(spam.path, p)))
all.spam <- sapply(spam.docs,function(p) get.msg(file.path(spam.path, p, sep='')))
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
stopwords()
all.spam <- sapply(spam.docs,function(p) get.msg(file.path(spam.path, p, sep='')))
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
spam.docs
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
get.msg(paste(spam.path,p,sep=""))
get.msg(paste(spam.path,spam.docs[1],sep=""))
get.msg(paste(spam.path,spam.docs[1],sep="/"))
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="/")))
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="/")))
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
setwd('C:\\Documents and Settings\\Macro\\Desktop\\Ivandata\\spam-filtering')
library('tm')
library('ggplot2')
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
# Return a single element vector of just the email body
# This is a very simple approach, as we are only using
# words as features
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
# Create a TermDocumentMatrix (TDM) from the corpus of SPAM email.
# The TDM control can be modified, and the sparsity level can be
# altered.  This TDM is used to create the feature set used to do
# train our classifier.
get.tdm <- function(doc.vec)
{
control <- list(stopwords = TRUE,
removePunctuation = TRUE,
removeNumbers = TRUE,
minDocFreq = 2)
doc.corpus <- Corpus(VectorSource(doc.vec))
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
# This function takes a file path to an email file and a string,
# the term parameter, and returns the count of that term in
# the email body.
count.word <- function(path, term)
{
msg <- get.msg(path)
msg.corpus <- Corpus(VectorSource(msg))
# Hard-coded TDM control
control <- list(stopwords = TRUE,
removePunctuation = TRUE,
removeNumbers = TRUE)
msg.tdm <- TermDocumentMatrix(msg.corpus, control)
word.freq <- rowSums(as.matrix(msg.tdm))
term.freq <- word.freq[which(names(word.freq) == term)]
# We use ifelse here because term.freq = NA if nothing is found
return(ifelse(length(term.freq) > 0, term.freq, 0))
}
# This is the our workhorse function for classifying email.  It takes
# two required paramters: a file path to an email to classify, and
# a data frame of the trained data.  The function also takes two
# optional parameters.  First, a prior over the probability that an email
# is SPAM, which we set to 0.5 (naive), and constant value for the
# probability on words in the email that are not in our training data.
# The function returns the naive Bayes probability that the given email
# is SPAM.
classify.email <- function(path, training.df, prior = 0.5, c = 1e-6)
{
# Here, we use many of the support functions to get the
# email text data in a workable format
msg <- get.msg(path)
msg.tdm <- get.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
# Find intersections of words
msg.match <- intersect(names(msg.freq), training.df$term)
# Now, we just perform the naive Bayes calculation
if(length(msg.match) < 1)
{
return(prior * c ^ (length(msg.freq)))
}
else
{
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
# With all of our support functions written, we can perform the classification.
# First, we create document corpus for spam messages
# Get all the SPAM-y email into a single vector
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
all.spam <- lapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
get.msg(file.path(spam.path, p))
get.msg(file.path(spam.path, spam.docs[8]))
get.msg(file.path(spam.path, spam.docs[9]))
get.msg(file.path(spam.path, spam.docs[10]))
get.msg(file.path(spam.path, spam.docs[11]))
get.msg(file.path(spam.path, spam.docs[12]))
for ( i in 1:500){
get.msg(file.path(spam.path, spam.docs[i]))
}
for ( i in 1:50){
get.msg(file.path(spam.path, spam.docs[i]))
}
get.msg(file.path(spam.path, spam.docs[12]))
for ( i in 1:10){
get.msg(file.path(spam.path, spam.docs[i]))
}
for ( i in 1:10){
I
}
for ( i in 1:10){
i
}
a <- for ( i in 1:10){
i
}
a
a <- for ( i in 1:10){
a[i]=i
}
a
a[1]
a[1]=1
a
a[2]
a[2]=2
a
a[2]
a <- for ( i in c(1:10)){
a[i]=i
}
a
a <- for ( i in 1:10){
a[i]=i
}
a
a[1]
class(a)
a <- as.matrix(a)
a <- as.vector(a)
a
a <- for ( i in 1:10){
a[i]=i
}
a
class(a)
a <- for ( i in 1:10){
as.vector(a)[i]=i
}
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
get.msg <- function(path)
{
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
?file
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
all.spam
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
library('tm')
spam.tdm <- get.tdm(all.spam)
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
setwd('C:\\Documents and Settings\\Macro\\Desktop\\Ivandata\\spam-filtering')
library('tm')
library('ggplot2')
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
# Return a single element vector of just the email body
# This is a very simple approach, as we are only using
# words as features
get.msg <- function(path)
{
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break
msg <- text[seq(which(text == "")[1] + 1, length(text), 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
# Get all the SPAM-y email into a single vector
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
# Create a TermDocumentMatrix (TDM) from the corpus of SPAM email.
# The TDM control can be modified, and the sparsity level can be
# altered.  This TDM is used to create the feature set used to do
# train our classifier.
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
head(spam.tdm )
head(spam.tdm)
summay(spam.tdm)
summary(spam.tdm)
spam.tdm
spam.matrix <- as.matrix(spam.tdm)
head(spam.matrix)
spam.counts <- rowSums(spam.matrix)
head(spam.counts)
spam.df <- data.frame(cbind(names(spam.counts),
as.numeric(spam.counts)),
stringsAsFactors = FALSE)
names(spam.counts)
head(spam.df)
names(spam.df) <- c("term", "frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.matrix[1,]
spam.occurrence <- sapply(1:nrow(spam.matrix),
function(i)
{
length(which(spam.matrix[i, ] > 0)) / ncol(spam.matrix)
})
head(spam.occurrence)
spam.density <- spam.df$frequency / sum(spam.df$frequency)
sum(spam.df$frequency)
spam.density
spam.df <- transform(spam.df,
density = spam.density,
occurrence = spam.occurrence)
spam.df[1,]
head(spam.df[with(spam.df, order(-occurrence)),])
ham.docs <- dir(easyham.path)
head(ham.docs)
ham.docs <- ham.docs[1:500]
ham.docs
